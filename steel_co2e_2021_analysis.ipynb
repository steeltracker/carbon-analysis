{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Amounts and Scope 1 and 2 Emission Values Per EAF Plant in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "import geopandas as gpd\n",
    "import mapclassify as mc\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing eGrid Data\n",
    "\n",
    "The EPA eGrida Data, which was available for 2021 at the time of download, contains the emissions intensity of electricity produced in each sub region. For this analysis, we assume that each steel plant is drawing 100% of its electricity from the grid (and the eGrid subregion that it is located within)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing grid region electricity values\n",
    "egrid2021_data = pd.read_excel('../data/eGRID2021_data.xlsx', sheet_name = \"SRL21\").clean_names(strip_underscores = True).drop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing state names and cleaning up rows in eGrid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning egrid data for usability\n",
    "emissions_by_subregion = egrid2021_data.copy()\n",
    "\n",
    "## Data Processing on columns\n",
    "emissions_by_subregion[\"co2e_lbs_per_mwh\"] = pd.to_numeric(emissions_by_subregion[\"egrid_subregion_annual_co2_equivalent_combustion_output_emission_rate_lb_mwh\"])\n",
    "emissions_by_subregion['subregion'] = emissions_by_subregion['egrid_subregion_acronym']\n",
    "emissions_by_subregion['subregion_name'] = emissions_by_subregion['egrid_subregion_name']\n",
    "emissions_by_subregion['co2e_tonnes_per_mwh'] = emissions_by_subregion['co2e_lbs_per_mwh'] / 2204.62262185\n",
    "\n",
    "## Filtering subregions\n",
    "excluded_subregions = [\"AKGD\", \"AKMS\", \"HIMS\", \"HIOA\", \"PRMS\"]\n",
    "emissions_by_subregion = emissions_by_subregion[~emissions_by_subregion['subregion'].isin(excluded_subregions)]\n",
    "\n",
    "## Selecting desired columns\n",
    "emissions_by_subregion = emissions_by_subregion[['subregion', 'subregion_name', 'co2e_tonnes_per_mwh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing GEM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_data_readin = pd.read_excel(\"../data/GEM_2022_data.xlsx\", sheet_name = \"Steel Plants\").clean_names(strip_underscores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering to only look at plants and data that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## eaf_capacity is in thousand tonnes per year and we are standardizing to tonnes\n",
    "gem_data_cleaned = gem_data_readin.copy()\n",
    "\n",
    "## Filtering to the specifications we need\n",
    "gem_data_cleaned = gem_data_cleaned[\n",
    "       (gem_data_cleaned['country'] == \"United States\") &\n",
    "       (gem_data_cleaned[\"status\"] == \"operating\") &\n",
    "       gem_data_cleaned['nominal_eaf_steel_capacity_ttpa'].notna()\n",
    "]\n",
    "\n",
    "## Needed to do this in another step to make sure start_date was properly filtered\n",
    "gem_data_cleaned = gem_data_cleaned[\n",
    "       (gem_data_cleaned['start_date'] < 2022) &\n",
    "       (~gem_data_cleaned['plant_id'].isin([\"SUS00009\", \"SUS00061\"]))\n",
    "]\n",
    "\n",
    "## Renaming columns\n",
    "gem_data_cleaned = gem_data_cleaned.rename(columns={'plant_name_english':'plant_name'\n",
    "                                          , 'subnational_unit_province_state':'state'\n",
    "                                          , 'location_address':'address'})\n",
    "\n",
    "## Converting EAF capacity from Thousand Tonnes to Tonnes\n",
    "gem_data_cleaned['eaf_capacity'] = pd.to_numeric(gem_data_cleaned['nominal_eaf_steel_capacity_ttpa'])\n",
    "gem_data_cleaned['max_tonnes_of_steel_producible_annually'] = gem_data_cleaned['eaf_capacity'] * 1000\n",
    "\n",
    "## Reordering columns to desired order\n",
    "gem_data_cleaned = gem_data_cleaned[['plant_id'\n",
    "         , 'plant_name'\n",
    "         , 'owner'\n",
    "         , 'coordinates'\n",
    "         , 'country'\n",
    "         , 'state'\n",
    "         , 'status'\n",
    "         , 'start_date'\n",
    "         , 'plant_age_years'\n",
    "         , 'max_tonnes_of_steel_producible_annually'\n",
    "         , 'municipality'\n",
    "         , 'address'\n",
    "         , 'category_steel_product'\n",
    "         , 'steel_products'\n",
    "         , 'responsiblesteel_certification']]\n",
    "\n",
    "## Removing columns we do not need\n",
    "gem_data = gem_data_cleaned.drop(columns=['country', 'start_date', 'status', 'responsiblesteel_certification'])\n",
    "\n",
    "## Separate the \"coordinates\" column into \"lat\" and \"lon\" columns\n",
    "gem_data[['lat', 'lon']] = gem_data['coordinates'].str.split(',', expand=True)\n",
    "\n",
    "## Remove the \"coordinates\" column\n",
    "gem_data.drop(columns=['coordinates'], inplace=True)\n",
    "\n",
    "## Reordering columns\n",
    "gem_data = gem_data[['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state', 'plant_age_years', 'max_tonnes_of_steel_producible_annually', 'municipality', 'address', 'category_steel_product', 'steel_products']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "## Reading in data\n",
    "subregion_shapes_raw = gpd.read_file(\"../data/egrid2020_subregions/eGRID2020_subregions.shp\").clean_names()\n",
    "\n",
    "## Filtering subregion shapes\n",
    "subregion_shapes = subregion_shapes_raw[~subregion_shapes_raw['zipsubregi'].isin([\"AKGD\", \"AKMS\", \"HIMS\", \"HIOA\", \"PRMS\"])]\n",
    "\n",
    "## Simplifying subregion shapes\n",
    "subregion_shapes['geometry'] = subregion_shapes.simplify(tolerance=0.0005)\n",
    "\n",
    "## Bringing in plant points\n",
    "plant_points = gpd.GeoDataFrame(gem_data, geometry=gpd.points_from_xy(gem_data['lon'], gem_data['lat']))\n",
    "plant_points.crs = \"EPSG:4326\"\n",
    "\n",
    "## Finding points that overlap with the egrid subregion\n",
    "## Removing columns we dont need and renaming the subregion column\n",
    "plant_emissions_by_subregion = gpd.sjoin(plant_points, subregion_shapes, op='within').drop(columns=['geometry', 'index_right', 'shape_leng', 'shape_le_1', 'shape_area']).rename(columns={'zipsubregi':'subregion'})\n",
    "\n",
    "plant_emissions_by_subregion = plant_emissions_by_subregion.merge(emissions_by_subregion, on='subregion', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing AISI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AISI_regions_readin = pd.read_excel(\"../data/AISI_regions.xlsx\", sheet_name=\"Regions by State\").clean_names(strip_underscores = True)\n",
    "\n",
    "AISI_data_readin = pd.read_excel(\"../data/AISI_data.xlsx\", sheet_name=\"AISI Production Values\").clean_names(strip_underscores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NE = Northeast\n",
    "\n",
    "GL = Great Lakes\n",
    "\n",
    "MW = Midwest\n",
    "\n",
    "S = Southern\n",
    "\n",
    "W = Western\n",
    "\n",
    "### Filtering AISI data, renaming columns, and selecting the weekly data and utilization rates we need\n",
    "\n",
    "**Uilization is based on tonnage capability to produce raw steel for a sustained full order book.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AISI_regions = AISI_regions_readin[AISI_regions_readin['steel_plant_in_gspt'] == \"yes\"]\n",
    "\n",
    "AISI_data = AISI_data_readin.rename(columns = {'north_east_region_capacity_utilization':'NE_util'\n",
    "                                          , 'great_lakes_region_capacity_utilization':'GL_util'\n",
    "                                          , 'midwest_region_capacity_utilization':'MW_util'\n",
    "                                          , 'southern_region_capacity_utilization':'S_util'\n",
    "                                          , 'western_region_capacity_utilization':'W_util'})\n",
    "\n",
    "AISI_data = AISI_data[['week_end_date', 'NE_util', 'GL_util', 'MW_util', 'S_util', 'W_util']]\n",
    "\n",
    "AISI_data = AISI_data[AISI_data['week_end_date'] <= '2022-01-01']\n",
    "\n",
    "AISI_data['week_end_date'] = pd.to_datetime(AISI_data['week_end_date'])\n",
    "\n",
    "AISI_data['week_end_date'] = AISI_data['week_end_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all of our data so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_plant_emissions = pd.merge(plant_emissions_by_subregion, AISI_regions, on = \"state\", how = \"left\")\n",
    "\n",
    "regional_plant_emissions = regional_plant_emissions.drop(['steel_plant_in_gspt', 'state_abbreviation'], axis = 1)\n",
    "\n",
    "conditions = [\n",
    "    regional_plant_emissions['municipality'].isin([\"Alton\", \"Sterling\", \"Peoria\", \"Granite City\", \"Mansfield\", \"Middletown\"])\n",
    "    , regional_plant_emissions['municipality'].isin([\"Riverdale\", \"Chicago\", \"Bourbonnais\", \"Cuyahoga Heights\", \"Cleveland\", \"Toledo\", \"Lorain\"])\n",
    "    , regional_plant_emissions['municipality'].isin([\"Mingo Junction\", \"Youngstown\", \"Canton\"])\n",
    "]\n",
    "\n",
    "choices = [\"Midwest\", \"Great Lakes\", \"North East\"]\n",
    "\n",
    "regional_plant_emissions['region'] = np.select(conditions, choices, default=regional_plant_emissions['region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining carbon intensity for eaf steel production and preparing data to calculate intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co2e_tonnes_per_mwh is from eGrid and is pounds of CO2e per MWH of electricity produced per grid location (not regional location)\n",
    "\n",
    "## Global Efficiency Intelligence states that it takes 710 KWH to produce 1 tonne of steel. \"Global Efficiency Intelligence: Industrial Electrification in U.S. States\"\n",
    "## MWH per tonne of steel\n",
    "eaf_MWH_per_tonne = 710 / 1000\n",
    "\n",
    "## emissions_intensity is tonnes of CO2e per tonne of steel (the amount of co2e produced for every tonne of steel produced)\n",
    "\n",
    "AISI_longer = AISI_data.melt(id_vars= 'week_end_date'\n",
    "                           , value_vars = ['NE_util', 'GL_util', 'MW_util', 'S_util', 'W_util']\n",
    "                           , var_name = 'region'\n",
    "                           , value_name = 'utilization')\n",
    "\n",
    "region_conditions = [\n",
    "  AISI_longer['region'] == \"NE_util\"\n",
    "  , AISI_longer['region'] == \"GL_util\"\n",
    "  , AISI_longer['region'] == \"MW_util\"\n",
    "  , AISI_longer['region'] == \"S_util\"\n",
    "  , AISI_longer['region'] == \"W_util\"\n",
    "]\n",
    "\n",
    "region_choices = [\"North East\", \"Great Lakes\", \"Midwest\", \"Southern\", \"Western\"]\n",
    "\n",
    "AISI_longer['region'] = np.select(region_conditions, region_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Weekly Scope 2 co2e values and putting it in long and wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "## Merging our two datasets based on the region column and defining new columns\n",
    "scope2_plant_emissions_long = pd.merge(regional_plant_emissions, AISI_longer, how = \"left\", on = \"region\")\n",
    "\n",
    "## Creating relavent columns\n",
    "scope2_plant_emissions_long['estimated_emissions_intensity_tonne_per_tonne_scope2'] = scope2_plant_emissions_long['co2e_tonnes_per_mwh'] * eaf_MWH_per_tonne\n",
    "scope2_plant_emissions_long['max_tonnes_of_steel_producible_weekly'] = scope2_plant_emissions_long['max_tonnes_of_steel_producible_annually'] / 52\n",
    "scope2_plant_emissions_long['scope2_co2e_tonnes_per_week'] = scope2_plant_emissions_long['utilization'] * scope2_plant_emissions_long['max_tonnes_of_steel_producible_weekly']\n",
    "\n",
    "scope2_plant_emissions_long = scope2_plant_emissions_long[[\"plant_id\"\n",
    "                                                            ,\"plant_name\"                                          \n",
    "                                                            ,\"owner\"                                               \n",
    "                                                            ,\"lat\"                                                 \n",
    "                                                            ,\"lon\"                                                 \n",
    "                                                            ,\"state\"                                               \n",
    "                                                            ,\"plant_age_years\"                                     \n",
    "                                                            ,\"municipality\"                                        \n",
    "                                                            ,\"address\"                                             \n",
    "                                                            ,\"category_steel_product\"                              \n",
    "                                                            ,\"steel_products\"                                      \n",
    "                                                            ,\"subregion\"                                           \n",
    "                                                            ,\"subregion_name\"                                      \n",
    "                                                            ,\"co2e_tonnes_per_mwh\"                                 \n",
    "                                                            ,\"region\"                                              \n",
    "                                                            ,\"week_end_date\"                                       \n",
    "                                                            ,\"utilization\"                                         \n",
    "                                                            ,\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    "                                                            ,\"max_tonnes_of_steel_producible_annually\"             \n",
    "                                                            ,\"max_tonnes_of_steel_producible_weekly\"               \n",
    "                                                            ,\"scope2_co2e_tonnes_per_week\"]]\n",
    "\n",
    "## Rounding the data\n",
    "scope2_plant_emissions_long_rounded = scope2_plant_emissions_long.round(2)\n",
    "\n",
    "## Transferring each week to be its own column\n",
    "scope2_plant_emissions_wide = scope2_plant_emissions_long_rounded.drop(columns = ['utilization']).pivot(\n",
    "    index = ['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state',\n",
    "       'plant_age_years', 'municipality', 'address', 'category_steel_product',\n",
    "       'steel_products', 'subregion', 'subregion_name', 'co2e_tonnes_per_mwh',\n",
    "       'region',\n",
    "       'estimated_emissions_intensity_tonne_per_tonne_scope2',\n",
    "       'max_tonnes_of_steel_producible_annually',\n",
    "       'max_tonnes_of_steel_producible_weekly']\n",
    "    , columns = 'week_end_date'\n",
    "    , values = 'scope2_co2e_tonnes_per_week'\n",
    ").reset_index(drop=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Scope 2 values for the complete 2021 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nyearly_scope2 = scope2_plant_emissions_long %>% \\n  group_by(plant_id, plant_name, address, lat, lon) %>% \\n  summarize(scope2_co2e_tonnes_2021 = sum(scope2_co2e_tonnes_per_week)) %>% \\n  ungroup()\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_scope2 = scope2_plant_emissions_long.groupby(['plant_id', 'plant_name', 'address', 'lat', 'lon']).agg(scope2_co2e_tonnes_2021 = ('scope2_co2e_tonnes_per_week', 'sum')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting zip codes to find matches with addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nchecking_unique_zipcodes_scope2 <- zipcode_extraction %>% \\n  group_by(zip_code) %>% \\n  summarise(count = n()) %>% \\n  filter(count < 2) %>% \\n  drop_na() %>%\\n  ungroup() %>% \\n  select(zip_code)\\n\\nunique_scope2_zip_codes <- checking_unique_zipcodes_scope2 %>% \\n  left_join(zipcode_extraction, by = \"zip_code\")\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making a copt of yearly_scope2 to work with\n",
    "zipcode_extraction = yearly_scope2.copy()\n",
    "\n",
    "## Extracting zip code from address\n",
    "zipcode_extraction['address2'] = yearly_scope2['address']\n",
    "\n",
    "## Separate the addresses based off of commas\n",
    "zipcode_extraction[['zip_code_part1', 'zip_code_part2', 'zip_code_part3', 'zip_code_part4', 'zip_code_part5']] = zipcode_extraction['address2'].str.split(',', expand = True)\n",
    "\n",
    "## Drop columns we do not need\n",
    "zipcode_extraction = zipcode_extraction.drop(columns = ['address2', 'zip_code_part1', 'zip_code_part5'])\n",
    "\n",
    "## Extract only the numeric portions of the addresses and put in NA's if there are no numbers\n",
    "zipcode_extraction['zip_code_part2'] = zipcode_extraction['zip_code_part2'].str.extract(r'(\\d+)')\n",
    "zipcode_extraction['zip_code_part3'] = zipcode_extraction['zip_code_part3'].str.extract(r'(\\d+)')\n",
    "zipcode_extraction['zip_code_part4'] = zipcode_extraction['zip_code_part4'].str.extract(r'(\\d+)')\n",
    "\n",
    "## Create zip_code column by selecting the non-null values from zip_code_part2, zip_code_part3, zip_code_part4\n",
    "zipcode_extraction['zip_code'] = zipcode_extraction['zip_code_part2'].fillna(zipcode_extraction['zip_code_part3']).fillna(zipcode_extraction['zip_code_part4'])\n",
    "\n",
    "## Dropping columns we do not need\n",
    "zipcode_extraction = zipcode_extraction.drop(columns = ['zip_code_part2', 'zip_code_part3', 'zip_code_part4'])\n",
    "\n",
    "checking_unique_zipcodes_scope2 = zipcode_extraction.groupby('zip_code').size().reset_index(name='count')\n",
    "\"\"\"\n",
    "\n",
    "checking_unique_zipcodes_scope2 <- zipcode_extraction %>% \n",
    "  group_by(zip_code) %>% \n",
    "  summarise(count = n()) %>% \n",
    "  filter(count < 2) %>% \n",
    "  drop_na() %>%\n",
    "  ungroup() %>% \n",
    "  select(zip_code)\n",
    "\n",
    "unique_scope2_zip_codes <- checking_unique_zipcodes_scope2 %>% \n",
    "  left_join(zipcode_extraction, by = \"zip_code\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>39701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>41405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>44510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>44704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>44903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>46167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>46368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>46721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>46725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>47933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>48161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>52761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>53080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>60914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>61081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>61641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>62002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>68701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>72315</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>72370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>72916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>75846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>76065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>77704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>78155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>81004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>84330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>85212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>97128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>98106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zip_code  count\n",
       "0     08872      1\n",
       "1     16045      1\n",
       "2     17113      1\n",
       "3     19230      1\n",
       "4     23805      1\n",
       "5     24017      1\n",
       "6     27922      1\n",
       "7     29033      1\n",
       "8     29450      1\n",
       "9     29540      1\n",
       "10    30121      1\n",
       "11    32234      1\n",
       "12    35064      1\n",
       "13    35212      1\n",
       "14    35404      1\n",
       "15    35673      1\n",
       "16    36505      1\n",
       "17    36513      1\n",
       "18    37921      1\n",
       "19    38109      1\n",
       "20    39701      1\n",
       "21    41045      1\n",
       "22    41405      1\n",
       "23    43515      1\n",
       "24    43938      1\n",
       "25    44125      1\n",
       "26    44510      1\n",
       "27    44704      1\n",
       "28    44706      1\n",
       "29    44903      1\n",
       "30    46167      1\n",
       "31    46368      1\n",
       "32    46721      1\n",
       "33    46725      1\n",
       "34    47933      1\n",
       "35    48161      1\n",
       "36    52761      1\n",
       "37    53080      1\n",
       "38    60619      1\n",
       "39    60914      1\n",
       "40    61081      1\n",
       "41    61641      1\n",
       "42    62002      1\n",
       "43    68701      1\n",
       "44    72315      2\n",
       "45    72370      1\n",
       "46    72916      1\n",
       "47    75846      1\n",
       "48    76065      1\n",
       "49    77704      1\n",
       "50    78155      1\n",
       "51    81004      1\n",
       "52    84330      1\n",
       "53    85212      1\n",
       "54    97128      1\n",
       "55    98106      1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_unique_zipcodes_scope2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('mikeys_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579423154b4eaee7bfe5a430418673f411175c3f3abce33f4969df0aa8270f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
