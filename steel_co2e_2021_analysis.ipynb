{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Amounts and Scope 1 and 2 Emission Values Per EAF Plant in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  ## Data manipulation\n",
    "import numpy as np  ## Numerical computing\n",
    "import janitor ## Cleaning column names\n",
    "import geopandas as gpd ## Reading in spatial data\n",
    "import re ## Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing eGrid Data\n",
    "\n",
    "The EPA eGrida Data, which was available for 2021 at the time of download, contains the emissions intensity of electricity produced in each sub region. For this analysis, we assume that each steel plant is drawing 100% of its electricity from the grid (and the eGrid subregion that it is located within)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing grid region electricity values\n",
    "egrid2021_data = pd.read_excel('../data/eGRID2021_data.xlsx', sheet_name = \"SRL21\").clean_names(strip_underscores = True).drop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing state names and cleaning up rows in eGrid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning egrid data for usability\n",
    "emissions_by_subregion = egrid2021_data.copy()\n",
    "\n",
    "## Data Processing on columns\n",
    "emissions_by_subregion[\"co2e_lbs_per_mwh\"] = pd.to_numeric(emissions_by_subregion[\"egrid_subregion_annual_co2_equivalent_combustion_output_emission_rate_lb_mwh\"])\n",
    "emissions_by_subregion['subregion'] = emissions_by_subregion['egrid_subregion_acronym']\n",
    "emissions_by_subregion['subregion_name'] = emissions_by_subregion['egrid_subregion_name']\n",
    "emissions_by_subregion['co2e_tonnes_per_mwh'] = emissions_by_subregion['co2e_lbs_per_mwh'] / 2204.62262185\n",
    "\n",
    "## Filtering out non-continental US subregions\n",
    "excluded_subregions = [\"AKGD\", \"AKMS\", \"HIMS\", \"HIOA\", \"PRMS\"]\n",
    "emissions_by_subregion = emissions_by_subregion[~emissions_by_subregion['subregion'].isin(excluded_subregions)]\n",
    "\n",
    "## Selecting desired columns\n",
    "emissions_by_subregion = emissions_by_subregion[['subregion', 'subregion_name', 'co2e_tonnes_per_mwh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing GEM data\n",
    "\n",
    "The GEM data was provided by our client Caitlin Swalec and includes the plant names, locations, and plant capacities that we will be reviewing for the EAF steel plants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_data_readin = pd.read_excel(\"../data/GEM_2022_data.xlsx\", sheet_name = \"Steel Plants\").clean_names(strip_underscores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering to only look at plants and data that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## eaf_capacity is in thousand tonnes per year and we are standardizing to tonnes\n",
    "gem_data_cleaned = gem_data_readin.copy()\n",
    "\n",
    "## Filtering to the specifications we need\n",
    "## Only looking at operating steel plants in the US\n",
    "gem_data_cleaned = gem_data_cleaned[\n",
    "       (gem_data_cleaned['country'] == \"United States\") &\n",
    "       (gem_data_cleaned[\"status\"] == \"operating\") &\n",
    "       gem_data_cleaned['nominal_eaf_steel_capacity_ttpa'].notna()\n",
    "]\n",
    "\n",
    "## Needed to do this in another step to make sure start_date was properly filtered\n",
    "## SUS00009 is not currently operating their EAF\n",
    "## SUS00061 has gone on strike for a long time so they are no longer operating\n",
    "gem_data_cleaned = gem_data_cleaned[\n",
    "       (gem_data_cleaned['start_date'] < 2022) &\n",
    "       (~gem_data_cleaned['plant_id'].isin([\"SUS00009\", \"SUS00061\"]))\n",
    "]\n",
    "\n",
    "## Renaming columns\n",
    "gem_data_cleaned = gem_data_cleaned.rename(columns={'plant_name_english':'plant_name'\n",
    "                                          , 'subnational_unit_province_state':'state'\n",
    "                                          , 'location_address':'address'})\n",
    "\n",
    "## Converting EAF capacity from Thousand Tonnes to Tonnes\n",
    "gem_data_cleaned['eaf_capacity'] = pd.to_numeric(gem_data_cleaned['nominal_eaf_steel_capacity_ttpa'])\n",
    "gem_data_cleaned['max_tonnes_of_steel_producible_annually'] = gem_data_cleaned['eaf_capacity'] * 1000\n",
    "\n",
    "## Reordering columns to desired order\n",
    "gem_data_cleaned = gem_data_cleaned[['plant_id'\n",
    "         , 'plant_name'\n",
    "         , 'owner'\n",
    "         , 'coordinates'\n",
    "         , 'country'\n",
    "         , 'state'\n",
    "         , 'status'\n",
    "         , 'start_date'\n",
    "         , 'plant_age_years'\n",
    "         , 'max_tonnes_of_steel_producible_annually'\n",
    "         , 'municipality'\n",
    "         , 'address'\n",
    "         , 'category_steel_product'\n",
    "         , 'steel_products'\n",
    "         , 'responsiblesteel_certification']]\n",
    "\n",
    "## Removing columns we do not need\n",
    "gem_data = gem_data_cleaned.drop(columns=['country', 'start_date', 'status', 'responsiblesteel_certification'])\n",
    "\n",
    "## Separate the \"coordinates\" column into \"lat\" and \"lon\" columns\n",
    "gem_data[['lat', 'lon']] = gem_data['coordinates'].str.split(',', expand=True)\n",
    "\n",
    "## Remove the \"coordinates\" column\n",
    "gem_data.drop(columns=['coordinates'], inplace=True)\n",
    "\n",
    "## Reordering columns\n",
    "gem_data = gem_data[['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state', 'plant_age_years', 'max_tonnes_of_steel_producible_annually', 'municipality', 'address', 'category_steel_product', 'steel_products']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eGrid data loaded below includes the electric grid subregions that we will be looking at. We are find which points overlap which with regions and are assigning those overlaps as the assigned region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "## Reading in data\n",
    "subregion_shapes_raw = gpd.read_file(\"../data/egrid2020_subregions/eGRID2020_subregions.shp\").clean_names()\n",
    "\n",
    "## Filtering subregion shapes\n",
    "subregion_shapes = subregion_shapes_raw[~subregion_shapes_raw['zipsubregi'].isin([\"AKGD\", \"AKMS\", \"HIMS\", \"HIOA\", \"PRMS\"])]\n",
    "\n",
    "## Simplifying subregion shapes\n",
    "subregion_shapes['geometry'] = subregion_shapes.simplify(tolerance=0.0005)\n",
    "\n",
    "## Bringing in plant points\n",
    "plant_points = gpd.GeoDataFrame(gem_data, geometry=gpd.points_from_xy(gem_data['lon'], gem_data['lat']))\n",
    "plant_points.crs = \"EPSG:4326\"\n",
    "\n",
    "## Finding points that overlap with the egrid subregion\n",
    "## Removing columns we dont need and renaming the subregion column\n",
    "plant_emissions_by_subregion = gpd.sjoin(plant_points, subregion_shapes, op = 'within').drop(columns = ['geometry', 'index_right', 'shape_leng', 'shape_le_1', 'shape_area']).rename(columns={'zipsubregi':'subregion'})\n",
    "\n",
    "## Combining our data based off of matching subregions\n",
    "plant_emissions_by_subregion = plant_emissions_by_subregion.merge(emissions_by_subregion, on = 'subregion', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing AISI data\n",
    "\n",
    "The American Iron and Steel Institute (AISI) is a trade association that represents the North American steel industry. It gathers and provides data related to steel production, consumption, trade, and other industry metrics. The AISI data covers various aspects of the steel industry, including information on steel production volumes, capacities, and utilization rates.\n",
    "\n",
    "We will be using these utilization rates in order to estimate the amount of steel produced per plant per week and per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AISI_regions_readin = pd.read_excel(\"../data/AISI_regions.xlsx\", sheet_name=\"Regions by State\").clean_names(strip_underscores = True)\n",
    "\n",
    "AISI_data_readin = pd.read_excel(\"../data/AISI_data.xlsx\", sheet_name=\"AISI Production Values\").clean_names(strip_underscores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region Abbreviations:\n",
    "\n",
    "NE = Northeast\n",
    "\n",
    "GL = Great Lakes\n",
    "\n",
    "MW = Midwest\n",
    "\n",
    "S = Southern\n",
    "\n",
    "W = Western\n",
    "\n",
    "### Filtering AISI data, renaming columns, and selecting the weekly data and utilization rates we need\n",
    "\n",
    "**Utilization is based on tonnage capability to produce raw steel for a sustained full order book.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering by \"yes\" to find plants that are in the data\n",
    "AISI_regions = AISI_regions_readin[AISI_regions_readin['steel_plant_in_gspt'] == \"yes\"]\n",
    "\n",
    "## Renaming columns for clarity\n",
    "AISI_data = AISI_data_readin.rename(columns = {'north_east_region_capacity_utilization':'NE_util'\n",
    "                                          , 'great_lakes_region_capacity_utilization':'GL_util'\n",
    "                                          , 'midwest_region_capacity_utilization':'MW_util'\n",
    "                                          , 'southern_region_capacity_utilization':'S_util'\n",
    "                                          , 'western_region_capacity_utilization':'W_util'})\n",
    "\n",
    "## Reordering columns\n",
    "AISI_data = AISI_data[['week_end_date', 'NE_util', 'GL_util', 'MW_util', 'S_util', 'W_util']]\n",
    "\n",
    "## Only looking at weeks before January 1, 2022\n",
    "AISI_data = AISI_data[AISI_data['week_end_date'] <= '2022-01-01']\n",
    "\n",
    "## Making week_end_date column into datetime\n",
    "AISI_data['week_end_date'] = pd.to_datetime(AISI_data['week_end_date'])\n",
    "\n",
    "## Shortening date to remove timestamps\n",
    "AISI_data['week_end_date'] = AISI_data['week_end_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all of our data so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging data based off of matching states\n",
    "regional_plant_emissions = pd.merge(plant_emissions_by_subregion, AISI_regions, on = \"state\", how = \"left\")\n",
    "\n",
    "regional_plant_emissions = regional_plant_emissions.drop(['steel_plant_in_gspt', 'state_abbreviation'], axis = 1)\n",
    "\n",
    "## assigning eGrid regions to multi-listed cities\n",
    "conditions = [\n",
    "    regional_plant_emissions['municipality'].isin([\"Alton\", \"Sterling\", \"Peoria\", \"Granite City\", \"Mansfield\", \"Middletown\"])\n",
    "    , regional_plant_emissions['municipality'].isin([\"Riverdale\", \"Chicago\", \"Bourbonnais\", \"Cuyahoga Heights\", \"Cleveland\", \"Toledo\", \"Lorain\"])\n",
    "    , regional_plant_emissions['municipality'].isin([\"Mingo Junction\", \"Youngstown\", \"Canton\"])\n",
    "]\n",
    "\n",
    "choices = [\"Midwest\", \"Great Lakes\", \"North East\"]\n",
    "\n",
    "regional_plant_emissions['region'] = np.select(conditions, choices, default=regional_plant_emissions['region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining carbon intensity for eaf steel production and preparing data to calculate intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co2e_tonnes_per_mwh is from eGrid and is pounds of CO2e per MWH of electricity produced per grid location (not regional location)\n",
    "\n",
    "## Global Efficiency Intelligence states that it takes 710 KWH to produce 1 tonne of steel. \"Global Efficiency Intelligence: Industrial Electrification in U.S. States\"\n",
    "## MWH per tonne of steel\n",
    "eaf_MWH_per_tonne = 710 / 1000\n",
    "\n",
    "## emissions_intensity is tonnes of CO2e per tonne of steel (the amount of co2e produced for every tonne of steel produced)\n",
    "\n",
    "AISI_longer = AISI_data.melt(id_vars= 'week_end_date'\n",
    "                           , value_vars = ['NE_util', 'GL_util', 'MW_util', 'S_util', 'W_util']\n",
    "                           , var_name = 'region'\n",
    "                           , value_name = 'utilization')\n",
    "\n",
    "region_conditions = [\n",
    "  AISI_longer['region'] == \"NE_util\"\n",
    "  , AISI_longer['region'] == \"GL_util\"\n",
    "  , AISI_longer['region'] == \"MW_util\"\n",
    "  , AISI_longer['region'] == \"S_util\"\n",
    "  , AISI_longer['region'] == \"W_util\"\n",
    "]\n",
    "\n",
    "region_choices = [\"North East\", \"Great Lakes\", \"Midwest\", \"Southern\", \"Western\"]\n",
    "\n",
    "AISI_longer['region'] = np.select(region_conditions, region_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Weekly Scope 2 co2e values and putting it in long and wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "## Merging our two datasets based on the region column and defining new columns\n",
    "scope2_plant_emissions_long = pd.merge(regional_plant_emissions, AISI_longer, how = \"left\", on = \"region\")\n",
    "\n",
    "## Creating relavent columns\n",
    "scope2_plant_emissions_long['estimated_emissions_intensity_tonne_per_tonne_scope2'] = scope2_plant_emissions_long['co2e_tonnes_per_mwh'] * eaf_MWH_per_tonne\n",
    "scope2_plant_emissions_long['max_tonnes_of_steel_producible_weekly'] = scope2_plant_emissions_long['max_tonnes_of_steel_producible_annually'] / 52\n",
    "scope2_plant_emissions_long['scope2_co2e_tonnes_per_week'] = scope2_plant_emissions_long['utilization'] * scope2_plant_emissions_long['max_tonnes_of_steel_producible_weekly'] * scope2_plant_emissions_long['estimated_emissions_intensity_tonne_per_tonne_scope2']\n",
    "\n",
    "scope2_plant_emissions_long = scope2_plant_emissions_long[[\"plant_id\"\n",
    "                                                            ,\"plant_name\"                                          \n",
    "                                                            ,\"owner\"                                               \n",
    "                                                            ,\"lat\"                                                 \n",
    "                                                            ,\"lon\"                                                 \n",
    "                                                            ,\"state\"                                               \n",
    "                                                            ,\"plant_age_years\"                                     \n",
    "                                                            ,\"municipality\"                                        \n",
    "                                                            ,\"address\"                                             \n",
    "                                                            ,\"category_steel_product\"                              \n",
    "                                                            ,\"steel_products\"                                      \n",
    "                                                            ,\"subregion\"                                           \n",
    "                                                            ,\"subregion_name\"                                      \n",
    "                                                            ,\"co2e_tonnes_per_mwh\"                                 \n",
    "                                                            ,\"region\"                                              \n",
    "                                                            ,\"week_end_date\"                                       \n",
    "                                                            ,\"utilization\"                                         \n",
    "                                                            ,\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    "                                                            ,\"max_tonnes_of_steel_producible_annually\"             \n",
    "                                                            ,\"max_tonnes_of_steel_producible_weekly\"               \n",
    "                                                            ,\"scope2_co2e_tonnes_per_week\"]]\n",
    "\n",
    "## Rounding the data\n",
    "scope2_plant_emissions_long_rounded = scope2_plant_emissions_long.round(2)\n",
    "\n",
    "## Transferring each week to be its own column\n",
    "scope2_plant_emissions_wide = scope2_plant_emissions_long_rounded.drop(columns = ['utilization']).pivot(\n",
    "    index = ['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state',\n",
    "       'plant_age_years', 'municipality', 'address', 'category_steel_product',\n",
    "       'steel_products', 'subregion', 'subregion_name', 'co2e_tonnes_per_mwh',\n",
    "       'region',\n",
    "       'estimated_emissions_intensity_tonne_per_tonne_scope2',\n",
    "       'max_tonnes_of_steel_producible_annually',\n",
    "       'max_tonnes_of_steel_producible_weekly']\n",
    "    , columns = 'week_end_date'\n",
    "    , values = 'scope2_co2e_tonnes_per_week'\n",
    ").reset_index(drop=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Scope 2 values for the complete 2021 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_scope2 = scope2_plant_emissions_long.groupby(['plant_id', 'plant_name', 'address', 'lat', 'lon']).agg(scope2_co2e_tonnes_2021 = ('scope2_co2e_tonnes_per_week', 'sum')).reset_index()\n",
    "\n",
    "yearly_scope2 = yearly_scope2.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting zip codes to find matches with addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a copy of yearly_scope2 to work with\n",
    "zipcode_extraction = yearly_scope2.copy()\n",
    "\n",
    "## Extracting zip code from address\n",
    "zipcode_extraction['address2'] = yearly_scope2['address']\n",
    "\n",
    "## Separate the addresses based off of commas\n",
    "zipcode_extraction[['zip_code_part1', 'zip_code_part2', 'zip_code_part3', 'zip_code_part4', 'zip_code_part5']] = zipcode_extraction['address2'].str.split(',', expand = True)\n",
    "\n",
    "## Drop columns we do not need\n",
    "zipcode_extraction = zipcode_extraction.drop(columns = ['address2', 'zip_code_part1', 'zip_code_part5'])\n",
    "\n",
    "## Extract only the numeric portions of the addresses and put in NA's if there are no numbers\n",
    "zipcode_extraction['zip_code_part2'] = zipcode_extraction['zip_code_part2'].str.extract(r'(\\d+)')\n",
    "zipcode_extraction['zip_code_part3'] = zipcode_extraction['zip_code_part3'].str.extract(r'(\\d+)')\n",
    "zipcode_extraction['zip_code_part4'] = zipcode_extraction['zip_code_part4'].str.extract(r'(\\d+)')\n",
    "\n",
    "## Create zip_code column by selecting the non-null values from zip_code_part2, zip_code_part3, zip_code_part4\n",
    "zipcode_extraction['zip_code'] = zipcode_extraction['zip_code_part2'].fillna(zipcode_extraction['zip_code_part3']).fillna(zipcode_extraction['zip_code_part4'])\n",
    "\n",
    "## Dropping columns we do not need\n",
    "zipcode_extraction = zipcode_extraction.drop(columns = ['zip_code_part2', 'zip_code_part3', 'zip_code_part4'])\n",
    "zipcode_extraction[\"zip_code\"] = pd.to_numeric(zipcode_extraction[\"zip_code\"])\n",
    "\n",
    "## Finding which zip codes only occur once and extracting those\n",
    "checking_unique_zipcodes_scope2 = zipcode_extraction.groupby('zip_code').size().reset_index(name = 'count')\n",
    "checking_unique_zipcodes_scope2 = checking_unique_zipcodes_scope2[checking_unique_zipcodes_scope2['count'] < 2].dropna().reset_index()\n",
    "checking_unique_zipcodes_scope2 = checking_unique_zipcodes_scope2[['zip_code']]\n",
    "\n",
    "## Combining these zip codes back to the original data in order to only merge based off of the unique zip codes we found\n",
    "unique_scope2_zipcodes = pd.merge(checking_unique_zipcodes_scope2, zipcode_extraction, how = \"left\", on = \"zip_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Greenhouse Gas Emissions data (scope 1) and extracting the non-repeating zip codes\n",
    "\n",
    "The Greenhouse Gas Emissions data we are using includes emissions data of co2 equivalences from steel plants in the United States. We assume that this data is scope 1 and does not include any scope 2 sources. This data includes steel plant names, companies, locations, and emissions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope1_readin = pd.read_excel(\"../data/GHG_flight_scope1.xls\", skiprows = 5, na_values = ['', 0]).clean_names(strip_underscores = True)\n",
    "\n",
    "## Making 0 values to NA to align with R code. Python was not reading them in as NA to begin with\n",
    "scope1_readin['ghg_quantity_metric_tons_co2e'] = scope1_readin['ghg_quantity_metric_tons_co2e'].replace(0, np.nan)\n",
    "\n",
    "scope1 = scope1_readin[['zip_code', 'ghg_quantity_metric_tons_co2e', 'ghgrp_id']].dropna()\n",
    "\n",
    "## Finding which zip codes only occur once and extracting those\n",
    "checking_unique_zipcodes_scope1 = scope1.groupby('zip_code').size().reset_index(name = 'count')\n",
    "checking_unique_zipcodes_scope1 = checking_unique_zipcodes_scope1[checking_unique_zipcodes_scope1['count'] < 2].dropna().reset_index()\n",
    "checking_unique_zipcodes_scope1 = checking_unique_zipcodes_scope1[['zip_code']]\n",
    "\n",
    "## Combining these zip codes back to the original data in order to only merge based off of the unique zip codes we found\n",
    "unique_scope1_zipcodes = pd.merge(checking_unique_zipcodes_scope1, scope1, how = \"left\", on = \"zip_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining scope 1 and scope 2 unique zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually checked zip codes and addresses and plant names and the following are for sure a match\n",
    "scope_1_and_2_zipcode_matches_all_columns = pd.merge(unique_scope1_zipcodes, unique_scope2_zipcodes, on = \"zip_code\", how = \"inner\").dropna().rename(columns = {'ghg_quantity_metric_tons_co2e':'scope1_co2e_tonnes_2021'})\n",
    "\n",
    "## Reading \n",
    "scope_1_and_2_zipcode_matches = scope_1_and_2_zipcode_matches_all_columns.reindex(columns=[\"zip_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anti-Joining to find remaining zip codes that had not matched and manually matching them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anti-Joining to find remaining zip codes that had not matched and manually matching them\n",
    "remaining_zipcodes = pd.merge(zipcode_extraction, scope_1_and_2_zipcode_matches, on = \"zip_code\", how = \"left\", indicator = True)\n",
    "remaining_zipcodes = remaining_zipcodes[remaining_zipcodes['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "corrected_ghgids = remaining_zipcodes.copy()\n",
    "\n",
    "## Correctly matching the zip codes and assigning the plant id equivalents between both datasets \n",
    "ghgid_conditions = [\n",
    "  remaining_zipcodes['plant_id'] == \"SUS00002\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00007\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00015\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00042\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00019\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00025\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00032\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00058\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00029\"\n",
    "]\n",
    "\n",
    "ghgid_choices = [\n",
    "  \"1003268\"\n",
    ", \"1003668\"\n",
    ", \"1000394\"\n",
    ", \"1004616\"\n",
    ", \"1002977\"\n",
    ", \"1007642\"\n",
    ", \"1007921\"\n",
    ", \"1007348\"\n",
    ", \"1005700\"]\n",
    "\n",
    "corrected_ghgids['ghgrp_id'] = np.select(ghgid_conditions, ghgid_choices, default=remaining_zipcodes['plant_id'])\n",
    "\n",
    "corrected_ghgids['ghgrp_id'] = pd.to_numeric(corrected_ghgids['ghgrp_id'])\n",
    "\n",
    "corrected_ghgids = pd.merge(corrected_ghgids, scope1, how = \"left\", on = \"ghgrp_id\").drop(columns = ['zip_code_x', 'zip_code_y']).rename(columns = {'ghg_quantity_metric_tons_co2e':'scope1_co2e_tonnes_2021'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all of our data to get a final dataset with scope 1 and 2 2021 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the total amount of emissions per plant per year \n",
    "scope_1_and_2_emissions_2021_prestep = pd.merge(scope_1_and_2_zipcode_matches_all_columns, corrected_ghgids, how = \"outer\").drop(columns = 'zip_code')\n",
    "scope_1_and_2_emissions_2021_prestep['total_co2e_tonnes_2021'] = scope_1_and_2_emissions_2021_prestep['scope1_co2e_tonnes_2021'] + scope_1_and_2_emissions_2021_prestep['scope2_co2e_tonnes_2021']\n",
    "# scope_1_and_2_emissions_2021_prestep['zip_code'] = scope_1_and_2_emissions_2021_prestep['zip_code'].apply(int)\n",
    "\n",
    "scope_1_and_2_emissions_2021 = pd.merge(scope_1_and_2_emissions_2021_prestep, scope2_plant_emissions_long, how = \"left\").drop(columns = ['week_end_date', 'utilization', 'estimated_emissions_intensity_tonne_per_tonne_scope2', 'max_tonnes_of_steel_producible_weekly', 'scope2_co2e_tonnes_per_week']).drop_duplicates().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding on the matched columns and id numbers onto our scope 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "## Finding weekly scope 2 values first\n",
    "weekly_scope2_plant_emissions_long = pd.merge(scope_1_and_2_emissions_2021_prestep, scope2_plant_emissions_long, how = \"left\").drop(columns = ['total_co2e_tonnes_2021', 'scope1_co2e_tonnes_2021', 'scope2_co2e_tonnes_2021']).round(3)\n",
    "\n",
    "weekly_scope2_plant_emissions_long = weekly_scope2_plant_emissions_long[[\"plant_id\"                                            \n",
    ",\"ghgrp_id\"                                            \n",
    ",\"plant_name\"                                          \n",
    ",\"lat\"                                                 \n",
    ",\"lon\"                                                 \n",
    ",\"address\"                                             \n",
    ",\"owner\"                                               \n",
    ",\"state\"                                               \n",
    ",\"plant_age_years\"                                     \n",
    ",\"municipality\"                                        \n",
    ",\"category_steel_product\"                              \n",
    ",\"steel_products\"                                      \n",
    ",\"subregion\"                                           \n",
    ",\"subregion_name\"                                      \n",
    ",\"region\"                                              \n",
    ",\"week_end_date\"                                       \n",
    ",\"utilization\"                                         \n",
    ",\"co2e_tonnes_per_mwh\"                                 \n",
    ",\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    ",\"max_tonnes_of_steel_producible_annually\"             \n",
    ",\"max_tonnes_of_steel_producible_weekly\"               \n",
    ",\"scope2_co2e_tonnes_per_week\"]]\n",
    "\n",
    "weekly_scope2_plant_emissions_wide = weekly_scope2_plant_emissions_long.drop(columns = ['utilization']).pivot(\n",
    "    index = [\"plant_id\"                                            \n",
    ",\"ghgrp_id\"                                            \n",
    ",\"plant_name\"                                          \n",
    ",\"lat\"                                                 \n",
    ",\"lon\"                                                 \n",
    ",\"address\"                                             \n",
    ",\"owner\"                                               \n",
    ",\"state\"                                               \n",
    ",\"plant_age_years\"                                     \n",
    ",\"municipality\"                                        \n",
    ",\"category_steel_product\"                              \n",
    ",\"steel_products\"                                      \n",
    ",\"subregion\"                                           \n",
    ",\"subregion_name\"                                      \n",
    ",\"region\"                                                                                                                         \n",
    ",\"co2e_tonnes_per_mwh\"                                 \n",
    ",\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    ",\"max_tonnes_of_steel_producible_annually\"             \n",
    ",\"max_tonnes_of_steel_producible_weekly\"               ]\n",
    "    , columns = 'week_end_date'\n",
    "    , values = 'scope2_co2e_tonnes_per_week'\n",
    ").reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our annual 2021 data into weekly to see breakdown of weekly co2e productions that include scope 1 AND scope 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "weekly_scope_1_and_2_long = pd.merge(scope_1_and_2_emissions_2021_prestep, scope2_plant_emissions_long)\n",
    "\n",
    "weekly_scope_1_and_2_long['scope1_tonnes_of_co2e_per_week'] = weekly_scope_1_and_2_long['scope1_co2e_tonnes_2021'] / 52\n",
    "weekly_scope_1_and_2_long['total_weekly_co2e_tonnes'] = weekly_scope_1_and_2_long['scope1_tonnes_of_co2e_per_week'] + weekly_scope_1_and_2_long['scope2_co2e_tonnes_per_week'].drop(columns = ['total_co2e_tonnes_2021', 'scope1_co2e_tonnes_2021', 'scope2_co2e_tonnes_2021'])\n",
    "weekly_scope_1_and_2_long = weekly_scope_1_and_2_long[[\"plant_id\"                                            \n",
    ",\"ghgrp_id\"                                            \n",
    ",\"plant_name\"                                          \n",
    ",\"lat\"                                                 \n",
    ",\"lon\"                                                 \n",
    ",\"address\"                                             \n",
    ",\"owner\"                                               \n",
    ",\"state\"                                               \n",
    ",\"plant_age_years\"                                     \n",
    ",\"municipality\"                                        \n",
    ",\"category_steel_product\"                              \n",
    ",\"steel_products\"                                      \n",
    ",\"subregion\"                                           \n",
    ",\"subregion_name\"                                      \n",
    ",\"region\"                                              \n",
    ",\"week_end_date\"                                       \n",
    ",\"utilization\"                                         \n",
    ",\"co2e_tonnes_per_mwh\"                                 \n",
    ",\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    ",\"max_tonnes_of_steel_producible_annually\"             \n",
    ",\"max_tonnes_of_steel_producible_weekly\"               \n",
    ",\"scope2_co2e_tonnes_per_week\"                         \n",
    ",\"scope1_tonnes_of_co2e_per_week\"                      \n",
    ",\"total_weekly_co2e_tonnes\"  ]]\n",
    "\n",
    "\n",
    "weekly_scope_1_and_2_wide = weekly_scope_1_and_2_long.drop(columns = ['utilization', 'scope2_co2e_tonnes_per_week']).pivot(\n",
    "    index = [\"plant_id\"                                            \n",
    ",\"ghgrp_id\"                                            \n",
    ",\"plant_name\"                                          \n",
    ",\"lat\"                                                 \n",
    ",\"lon\"                                                 \n",
    ",\"address\"                                             \n",
    ",\"owner\"                                               \n",
    ",\"state\"                                               \n",
    ",\"plant_age_years\"                                     \n",
    ",\"municipality\"                                        \n",
    ",\"category_steel_product\"                              \n",
    ",\"steel_products\"                                      \n",
    ",\"subregion\"                                           \n",
    ",\"subregion_name\"                                      \n",
    ",\"region\"                                                                                      \n",
    ",\"co2e_tonnes_per_mwh\"                                 \n",
    ",\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    ",\"max_tonnes_of_steel_producible_annually\"             \n",
    ",\"max_tonnes_of_steel_producible_weekly\"                                       \n",
    ",\"scope1_tonnes_of_co2e_per_week\"]\n",
    "    , columns = 'week_end_date'\n",
    "    , values = 'total_weekly_co2e_tonnes'\n",
    ").reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the amount of steel produced weekly and annually (_long and _wide denote datasets with weekly values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "### Weekly plant productions long\n",
    "plant_productions_long = scope2_plant_emissions_long.drop(columns = ['scope2_co2e_tonnes_per_week'])\n",
    "\n",
    "plant_productions_long['tonnes_of_steel_produced'] = plant_productions_long['utilization'] * plant_productions_long['max_tonnes_of_steel_producible_weekly']\n",
    "\n",
    "## Rounding the data\n",
    "plant_productions_long_rounded = plant_productions_long.round(3)\n",
    "\n",
    "## Amount of steel produced per week\n",
    "plant_productions_wide = plant_productions_long_rounded.drop(columns = ['utilization']).pivot(\n",
    "    index = ['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state',\n",
    "       'plant_age_years', 'municipality', 'address', 'category_steel_product',\n",
    "       'steel_products', 'subregion', 'subregion_name', 'co2e_tonnes_per_mwh',\n",
    "       'region',\n",
    "       'estimated_emissions_intensity_tonne_per_tonne_scope2',\n",
    "       'max_tonnes_of_steel_producible_annually',\n",
    "       'max_tonnes_of_steel_producible_weekly']\n",
    "    , columns = 'week_end_date'\n",
    "    , values = 'tonnes_of_steel_produced'\n",
    ").reset_index(drop=False)\n",
    "\n",
    "### 2021 Year ----\n",
    "## Amount of steel produced in 2021\n",
    "plant_productions_2021 = plant_productions_long_rounded.drop(columns = ['week_end_date', 'utilization'])\n",
    "\n",
    "plant_productions_2021 = plant_productions_2021.groupby(['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state',\n",
    "       'plant_age_years', 'municipality', 'address', 'category_steel_product',\n",
    "       'steel_products', 'subregion', 'subregion_name', 'co2e_tonnes_per_mwh',\n",
    "       'region', 'estimated_emissions_intensity_tonne_per_tonne_scope2',\n",
    "       'max_tonnes_of_steel_producible_annually',\n",
    "       'max_tonnes_of_steel_producible_weekly']).sum().reset_index().rename(columns = {'tonnes_of_steel_produced':'total_tonnes_steel_produced_2021'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steel_plant_emissions_and_productions_2021 = pd.merge(plant_productions_2021, scope_1_and_2_emissions_2021, how = 'left')\n",
    "\n",
    "total_steel_plant_emissions_and_productions_2021['emissions_intensity_co2e_tonne_per_tonne'] = total_steel_plant_emissions_and_productions_2021['total_co2e_tonnes_2021'] / total_steel_plant_emissions_and_productions_2021['total_tonnes_steel_produced_2021']\n",
    "\n",
    "total_steel_plant_emissions_and_productions_2021['estimated_emissions_intensity_tonne_per_tonne_scope1'] = total_steel_plant_emissions_and_productions_2021['scope1_co2e_tonnes_2021'] / total_steel_plant_emissions_and_productions_2021['total_tonnes_steel_produced_2021']\n",
    "\n",
    "total_steel_plant_emissions_and_productions_2021 = total_steel_plant_emissions_and_productions_2021[[\"plant_id\"                                            \n",
    ", \"ghgrp_id\"                                            \n",
    ", \"plant_name\"                                          \n",
    ", \"owner\"                                               \n",
    ", \"lat\"                                                 \n",
    ", \"lon\"                                                 \n",
    ", \"state\"                                               \n",
    ", \"plant_age_years\"                                     \n",
    ", \"municipality\"                                        \n",
    ", \"address\"                                             \n",
    ", \"category_steel_product\"                              \n",
    ", \"steel_products\"                                      \n",
    ", \"subregion\"                                           \n",
    ", \"subregion_name\"                                      \n",
    ", \"co2e_tonnes_per_mwh\"                                 \n",
    ", \"region\"                                              \n",
    ", \"estimated_emissions_intensity_tonne_per_tonne_scope1\"\n",
    ", \"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    ", \"emissions_intensity_co2e_tonne_per_tonne\"            \n",
    ", \"max_tonnes_of_steel_producible_annually\"             \n",
    ", \"max_tonnes_of_steel_producible_weekly\"               \n",
    ", \"scope1_co2e_tonnes_2021\"                             \n",
    ", \"scope2_co2e_tonnes_2021\"                             \n",
    ", \"total_co2e_tonnes_2021\"                              \n",
    ", \"total_tonnes_steel_produced_2021\"   ]].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly scope 1 and 2 co2e wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_scope_1_and_2_wide.to_csv('output-data/weekly_scope1_scope2_steel_plant_emissions_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly scope 1 and 2 co2e long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_scope_1_and_2_long.to_csv('output-data/weekly_scope1_scope2_steel_plant_emissions_2021_long.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly scope 2 co2e wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_scope2_plant_emissions_wide.to_csv('output-data/weekly_scope2_plant_emissions_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly scope 2 co2e long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_scope2_plant_emissions_long.to_csv('output-data/weekly_scope2_plant_emissions_2021_long.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total annual productions and scope 1 and 2 co2e emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steel_plant_emissions_and_productions_2021.to_csv('output-data/2021_steel_plant_emissions_and_productions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly steel plant productions wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_productions_wide.to_csv('output-data/weekly_steel_production.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly steel plant productions long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_productions_long.to_csv('output-data/weekly_steel_production_long.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('mikeys_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579423154b4eaee7bfe5a430418673f411175c3f3abce33f4969df0aa8270f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
