{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Amounts and Scope 1 and 2 Emission Values Per EAF Plant in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "import geopandas as gpd\n",
    "import mapclassify as mc\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing eGrid Data\n",
    "\n",
    "The EPA eGrida Data, which was available for 2021 at the time of download, contains the emissions intensity of electricity produced in each sub region. For this analysis, we assume that each steel plant is drawing 100% of its electricity from the grid (and the eGrid subregion that it is located within)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing grid region electricity values\n",
    "egrid2021_data = pd.read_excel('../data/eGRID2021_data.xlsx', sheet_name = \"SRL21\").clean_names(strip_underscores = True).drop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing state names and cleaning up rows in eGrid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning egrid data for usability\n",
    "emissions_by_subregion = egrid2021_data.copy()\n",
    "\n",
    "## Data Processing on columns\n",
    "emissions_by_subregion[\"co2e_lbs_per_mwh\"] = pd.to_numeric(emissions_by_subregion[\"egrid_subregion_annual_co2_equivalent_combustion_output_emission_rate_lb_mwh\"])\n",
    "emissions_by_subregion['subregion'] = emissions_by_subregion['egrid_subregion_acronym']\n",
    "emissions_by_subregion['subregion_name'] = emissions_by_subregion['egrid_subregion_name']\n",
    "emissions_by_subregion['co2e_tonnes_per_mwh'] = emissions_by_subregion['co2e_lbs_per_mwh'] / 2204.62262185\n",
    "\n",
    "## Filtering subregions\n",
    "excluded_subregions = [\"AKGD\", \"AKMS\", \"HIMS\", \"HIOA\", \"PRMS\"]\n",
    "emissions_by_subregion = emissions_by_subregion[~emissions_by_subregion['subregion'].isin(excluded_subregions)]\n",
    "\n",
    "## Selecting desired columns\n",
    "emissions_by_subregion = emissions_by_subregion[['subregion', 'subregion_name', 'co2e_tonnes_per_mwh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing GEM data\n",
    "\n",
    "The GEM data was provided by our client Caitlin Swalec and includes the plant names, locations, and plant capacities that we will be reviewing for the EAF steel plants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_data_readin = pd.read_excel(\"../data/GEM_2022_data.xlsx\", sheet_name = \"Steel Plants\").clean_names(strip_underscores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering to only look at plants and data that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## eaf_capacity is in thousand tonnes per year and we are standardizing to tonnes\n",
    "gem_data_cleaned = gem_data_readin.copy()\n",
    "\n",
    "## Filtering to the specifications we need\n",
    "gem_data_cleaned = gem_data_cleaned[\n",
    "       (gem_data_cleaned['country'] == \"United States\") &\n",
    "       (gem_data_cleaned[\"status\"] == \"operating\") &\n",
    "       gem_data_cleaned['nominal_eaf_steel_capacity_ttpa'].notna()\n",
    "]\n",
    "\n",
    "## Needed to do this in another step to make sure start_date was properly filtered\n",
    "gem_data_cleaned = gem_data_cleaned[\n",
    "       (gem_data_cleaned['start_date'] < 2022) &\n",
    "       (~gem_data_cleaned['plant_id'].isin([\"SUS00009\", \"SUS00061\"]))\n",
    "]\n",
    "\n",
    "## Renaming columns\n",
    "gem_data_cleaned = gem_data_cleaned.rename(columns={'plant_name_english':'plant_name'\n",
    "                                          , 'subnational_unit_province_state':'state'\n",
    "                                          , 'location_address':'address'})\n",
    "\n",
    "## Converting EAF capacity from Thousand Tonnes to Tonnes\n",
    "gem_data_cleaned['eaf_capacity'] = pd.to_numeric(gem_data_cleaned['nominal_eaf_steel_capacity_ttpa'])\n",
    "gem_data_cleaned['max_tonnes_of_steel_producible_annually'] = gem_data_cleaned['eaf_capacity'] * 1000\n",
    "\n",
    "## Reordering columns to desired order\n",
    "gem_data_cleaned = gem_data_cleaned[['plant_id'\n",
    "         , 'plant_name'\n",
    "         , 'owner'\n",
    "         , 'coordinates'\n",
    "         , 'country'\n",
    "         , 'state'\n",
    "         , 'status'\n",
    "         , 'start_date'\n",
    "         , 'plant_age_years'\n",
    "         , 'max_tonnes_of_steel_producible_annually'\n",
    "         , 'municipality'\n",
    "         , 'address'\n",
    "         , 'category_steel_product'\n",
    "         , 'steel_products'\n",
    "         , 'responsiblesteel_certification']]\n",
    "\n",
    "## Removing columns we do not need\n",
    "gem_data = gem_data_cleaned.drop(columns=['country', 'start_date', 'status', 'responsiblesteel_certification'])\n",
    "\n",
    "## Separate the \"coordinates\" column into \"lat\" and \"lon\" columns\n",
    "gem_data[['lat', 'lon']] = gem_data['coordinates'].str.split(',', expand=True)\n",
    "\n",
    "## Remove the \"coordinates\" column\n",
    "gem_data.drop(columns=['coordinates'], inplace=True)\n",
    "\n",
    "## Reordering columns\n",
    "gem_data = gem_data[['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state', 'plant_age_years', 'max_tonnes_of_steel_producible_annually', 'municipality', 'address', 'category_steel_product', 'steel_products']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eGrid data loaded below includes the electric grid subregions that we will be looking at. We are find which points overlap which with regions and are assigning those overlaps as the assigned region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "## Reading in data\n",
    "subregion_shapes_raw = gpd.read_file(\"../data/egrid2020_subregions/eGRID2020_subregions.shp\").clean_names()\n",
    "\n",
    "## Filtering subregion shapes\n",
    "subregion_shapes = subregion_shapes_raw[~subregion_shapes_raw['zipsubregi'].isin([\"AKGD\", \"AKMS\", \"HIMS\", \"HIOA\", \"PRMS\"])]\n",
    "\n",
    "## Simplifying subregion shapes\n",
    "subregion_shapes['geometry'] = subregion_shapes.simplify(tolerance=0.0005)\n",
    "\n",
    "## Bringing in plant points\n",
    "plant_points = gpd.GeoDataFrame(gem_data, geometry=gpd.points_from_xy(gem_data['lon'], gem_data['lat']))\n",
    "plant_points.crs = \"EPSG:4326\"\n",
    "\n",
    "## Finding points that overlap with the egrid subregion\n",
    "## Removing columns we dont need and renaming the subregion column\n",
    "plant_emissions_by_subregion = gpd.sjoin(plant_points, subregion_shapes, op='within').drop(columns=['geometry', 'index_right', 'shape_leng', 'shape_le_1', 'shape_area']).rename(columns={'zipsubregi':'subregion'})\n",
    "\n",
    "plant_emissions_by_subregion = plant_emissions_by_subregion.merge(emissions_by_subregion, on='subregion', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing AISI data\n",
    "\n",
    "The American Iron and Steel Institute (AISI) is a trade association that represents the North American steel industry. It gathers and provides data related to steel production, consumption, trade, and other industry metrics. The AISI data covers various aspects of the steel industry, including information on steel production volumes, capacities, and utilization rates.\n",
    "\n",
    "We will be using these utilization rates in order to estimate the amount of steel produced per plant per week and per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AISI_regions_readin = pd.read_excel(\"../data/AISI_regions.xlsx\", sheet_name=\"Regions by State\").clean_names(strip_underscores = True)\n",
    "\n",
    "AISI_data_readin = pd.read_excel(\"../data/AISI_data.xlsx\", sheet_name=\"AISI Production Values\").clean_names(strip_underscores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NE = Northeast\n",
    "\n",
    "GL = Great Lakes\n",
    "\n",
    "MW = Midwest\n",
    "\n",
    "S = Southern\n",
    "\n",
    "W = Western\n",
    "\n",
    "### Filtering AISI data, renaming columns, and selecting the weekly data and utilization rates we need\n",
    "\n",
    "**Uilization is based on tonnage capability to produce raw steel for a sustained full order book.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AISI_regions = AISI_regions_readin[AISI_regions_readin['steel_plant_in_gspt'] == \"yes\"]\n",
    "\n",
    "AISI_data = AISI_data_readin.rename(columns = {'north_east_region_capacity_utilization':'NE_util'\n",
    "                                          , 'great_lakes_region_capacity_utilization':'GL_util'\n",
    "                                          , 'midwest_region_capacity_utilization':'MW_util'\n",
    "                                          , 'southern_region_capacity_utilization':'S_util'\n",
    "                                          , 'western_region_capacity_utilization':'W_util'})\n",
    "\n",
    "AISI_data = AISI_data[['week_end_date', 'NE_util', 'GL_util', 'MW_util', 'S_util', 'W_util']]\n",
    "\n",
    "AISI_data = AISI_data[AISI_data['week_end_date'] <= '2022-01-01']\n",
    "\n",
    "AISI_data['week_end_date'] = pd.to_datetime(AISI_data['week_end_date'])\n",
    "\n",
    "AISI_data['week_end_date'] = AISI_data['week_end_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all of our data so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_plant_emissions = pd.merge(plant_emissions_by_subregion, AISI_regions, on = \"state\", how = \"left\")\n",
    "\n",
    "regional_plant_emissions = regional_plant_emissions.drop(['steel_plant_in_gspt', 'state_abbreviation'], axis = 1)\n",
    "\n",
    "conditions = [\n",
    "    regional_plant_emissions['municipality'].isin([\"Alton\", \"Sterling\", \"Peoria\", \"Granite City\", \"Mansfield\", \"Middletown\"])\n",
    "    , regional_plant_emissions['municipality'].isin([\"Riverdale\", \"Chicago\", \"Bourbonnais\", \"Cuyahoga Heights\", \"Cleveland\", \"Toledo\", \"Lorain\"])\n",
    "    , regional_plant_emissions['municipality'].isin([\"Mingo Junction\", \"Youngstown\", \"Canton\"])\n",
    "]\n",
    "\n",
    "choices = [\"Midwest\", \"Great Lakes\", \"North East\"]\n",
    "\n",
    "regional_plant_emissions['region'] = np.select(conditions, choices, default=regional_plant_emissions['region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining carbon intensity for eaf steel production and preparing data to calculate intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co2e_tonnes_per_mwh is from eGrid and is pounds of CO2e per MWH of electricity produced per grid location (not regional location)\n",
    "\n",
    "## Global Efficiency Intelligence states that it takes 710 KWH to produce 1 tonne of steel. \"Global Efficiency Intelligence: Industrial Electrification in U.S. States\"\n",
    "## MWH per tonne of steel\n",
    "eaf_MWH_per_tonne = 710 / 1000\n",
    "\n",
    "## emissions_intensity is tonnes of CO2e per tonne of steel (the amount of co2e produced for every tonne of steel produced)\n",
    "\n",
    "AISI_longer = AISI_data.melt(id_vars= 'week_end_date'\n",
    "                           , value_vars = ['NE_util', 'GL_util', 'MW_util', 'S_util', 'W_util']\n",
    "                           , var_name = 'region'\n",
    "                           , value_name = 'utilization')\n",
    "\n",
    "region_conditions = [\n",
    "  AISI_longer['region'] == \"NE_util\"\n",
    "  , AISI_longer['region'] == \"GL_util\"\n",
    "  , AISI_longer['region'] == \"MW_util\"\n",
    "  , AISI_longer['region'] == \"S_util\"\n",
    "  , AISI_longer['region'] == \"W_util\"\n",
    "]\n",
    "\n",
    "region_choices = [\"North East\", \"Great Lakes\", \"Midwest\", \"Southern\", \"Western\"]\n",
    "\n",
    "AISI_longer['region'] = np.select(region_conditions, region_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Weekly Scope 2 co2e values and putting it in long and wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/opt/miniconda3/envs/mikeys_env/lib/python3.10/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "## Merging our two datasets based on the region column and defining new columns\n",
    "scope2_plant_emissions_long = pd.merge(regional_plant_emissions, AISI_longer, how = \"left\", on = \"region\")\n",
    "\n",
    "## Creating relavent columns\n",
    "scope2_plant_emissions_long['estimated_emissions_intensity_tonne_per_tonne_scope2'] = scope2_plant_emissions_long['co2e_tonnes_per_mwh'] * eaf_MWH_per_tonne\n",
    "scope2_plant_emissions_long['max_tonnes_of_steel_producible_weekly'] = scope2_plant_emissions_long['max_tonnes_of_steel_producible_annually'] / 52\n",
    "scope2_plant_emissions_long['scope2_co2e_tonnes_per_week'] = scope2_plant_emissions_long['utilization'] * scope2_plant_emissions_long['max_tonnes_of_steel_producible_weekly']\n",
    "\n",
    "scope2_plant_emissions_long = scope2_plant_emissions_long[[\"plant_id\"\n",
    "                                                            ,\"plant_name\"                                          \n",
    "                                                            ,\"owner\"                                               \n",
    "                                                            ,\"lat\"                                                 \n",
    "                                                            ,\"lon\"                                                 \n",
    "                                                            ,\"state\"                                               \n",
    "                                                            ,\"plant_age_years\"                                     \n",
    "                                                            ,\"municipality\"                                        \n",
    "                                                            ,\"address\"                                             \n",
    "                                                            ,\"category_steel_product\"                              \n",
    "                                                            ,\"steel_products\"                                      \n",
    "                                                            ,\"subregion\"                                           \n",
    "                                                            ,\"subregion_name\"                                      \n",
    "                                                            ,\"co2e_tonnes_per_mwh\"                                 \n",
    "                                                            ,\"region\"                                              \n",
    "                                                            ,\"week_end_date\"                                       \n",
    "                                                            ,\"utilization\"                                         \n",
    "                                                            ,\"estimated_emissions_intensity_tonne_per_tonne_scope2\"\n",
    "                                                            ,\"max_tonnes_of_steel_producible_annually\"             \n",
    "                                                            ,\"max_tonnes_of_steel_producible_weekly\"               \n",
    "                                                            ,\"scope2_co2e_tonnes_per_week\"]]\n",
    "\n",
    "## Rounding the data\n",
    "scope2_plant_emissions_long_rounded = scope2_plant_emissions_long.round(2)\n",
    "\n",
    "## Transferring each week to be its own column\n",
    "scope2_plant_emissions_wide = scope2_plant_emissions_long_rounded.drop(columns = ['utilization']).pivot(\n",
    "    index = ['plant_id', 'plant_name', 'owner', 'lat', 'lon', 'state',\n",
    "       'plant_age_years', 'municipality', 'address', 'category_steel_product',\n",
    "       'steel_products', 'subregion', 'subregion_name', 'co2e_tonnes_per_mwh',\n",
    "       'region',\n",
    "       'estimated_emissions_intensity_tonne_per_tonne_scope2',\n",
    "       'max_tonnes_of_steel_producible_annually',\n",
    "       'max_tonnes_of_steel_producible_weekly']\n",
    "    , columns = 'week_end_date'\n",
    "    , values = 'scope2_co2e_tonnes_per_week'\n",
    ").reset_index(drop=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Scope 2 values for the complete 2021 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_scope2 = scope2_plant_emissions_long.groupby(['plant_id', 'plant_name', 'address', 'lat', 'lon']).agg(scope2_co2e_tonnes_2021 = ('scope2_co2e_tonnes_per_week', 'sum')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting zip codes to find matches with addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a copt of yearly_scope2 to work with\n",
    "zipcode_extraction = yearly_scope2.copy()\n",
    "\n",
    "## Extracting zip code from address\n",
    "zipcode_extraction['address2'] = yearly_scope2['address']\n",
    "\n",
    "## Separate the addresses based off of commas\n",
    "zipcode_extraction[['zip_code_part1', 'zip_code_part2', 'zip_code_part3', 'zip_code_part4', 'zip_code_part5']] = zipcode_extraction['address2'].str.split(',', expand = True)\n",
    "\n",
    "## Drop columns we do not need\n",
    "zipcode_extraction = zipcode_extraction.drop(columns = ['address2', 'zip_code_part1', 'zip_code_part5'])\n",
    "\n",
    "## Extract only the numeric portions of the addresses and put in NA's if there are no numbers\n",
    "zipcode_extraction['zip_code_part2'] = zipcode_extraction['zip_code_part2'].str.extract(r'(\\d+)')\n",
    "zipcode_extraction['zip_code_part3'] = zipcode_extraction['zip_code_part3'].str.extract(r'(\\d+)')\n",
    "zipcode_extraction['zip_code_part4'] = zipcode_extraction['zip_code_part4'].str.extract(r'(\\d+)')\n",
    "\n",
    "## Create zip_code column by selecting the non-null values from zip_code_part2, zip_code_part3, zip_code_part4\n",
    "zipcode_extraction['zip_code'] = zipcode_extraction['zip_code_part2'].fillna(zipcode_extraction['zip_code_part3']).fillna(zipcode_extraction['zip_code_part4'])\n",
    "\n",
    "## Dropping columns we do not need\n",
    "zipcode_extraction = zipcode_extraction.drop(columns = ['zip_code_part2', 'zip_code_part3', 'zip_code_part4'])\n",
    "zipcode_extraction[\"zip_code\"] = pd.to_numeric(zipcode_extraction[\"zip_code\"])\n",
    "\n",
    "checking_unique_zipcodes_scope2 = zipcode_extraction.groupby('zip_code').size().reset_index(name='count')\n",
    "checking_unique_zipcodes_scope2 = checking_unique_zipcodes_scope2[checking_unique_zipcodes_scope2['count'] < 2].dropna().reset_index()\n",
    "checking_unique_zipcodes_scope2 = checking_unique_zipcodes_scope2[['zip_code']]\n",
    "\n",
    "unique_scope2_zipcodes = pd.merge(checking_unique_zipcodes_scope2, zipcode_extraction, how = \"left\", on = \"zip_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Greenhouse Gas Emissions data (scope 1) and extracting the non-repeating zip codes\n",
    "\n",
    "The Greenhouse Gas Emissions data we are using includes emissions data of co2 equivalences from steel plants in the United States. We assume that this data is scope 1 and does not include any scope 2 sources. This data includes steel plant names, companies, locations, and emissions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope1_readin = pd.read_excel(\"../data/GHG_flight_scope1.xls\", skiprows = 5, na_values = ['', 0]).clean_names(strip_underscores = True)\n",
    "\n",
    "## Making 0 values to NA to align with R code. Python was not reading them in as NA to begin with\n",
    "scope1_readin['ghg_quantity_metric_tons_co2e'] = scope1_readin['ghg_quantity_metric_tons_co2e'].replace(0, np.nan)\n",
    "\n",
    "scope1 = scope1_readin[['zip_code', 'ghg_quantity_metric_tons_co2e', 'ghgrp_id']].dropna()\n",
    "\n",
    "checking_unique_zipcodes_scope1 = scope1.groupby('zip_code').size().reset_index(name = 'count')\n",
    "checking_unique_zipcodes_scope1 = checking_unique_zipcodes_scope1[checking_unique_zipcodes_scope1['count'] < 2].dropna().reset_index()\n",
    "checking_unique_zipcodes_scope1 = checking_unique_zipcodes_scope1[['zip_code']]\n",
    "\n",
    "unique_scope1_zipcodes = pd.merge(checking_unique_zipcodes_scope1, scope1, how = \"left\", on = \"zip_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining scope 1 and scope 2 unique zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually checked zip codes and addresses and plant names and the following are for sure a match\n",
    "scope_1_and_2_zipcode_matches = pd.merge(unique_scope1_zipcodes, unique_scope2_zipcodes, on = \"zip_code\", how = \"inner\").dropna().rename(columns = {'ghg_quantity_metric_tons_co2e':'scope1_co2e_tonnes_2021'}).reindex(columns=[\"zip_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anti-Joining to find remaining zip codes that had not matched and manually matching them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n %>% \\n  mutate(ghgrp_id = case_when(plant_id == \"SUS00002\" ~ \"1003268\"\\n                              , plant_id == \"SUS00007\" ~ \"1003668\"\\n                              , plant_id == \"SUS00015\" ~ \"1000394\"\\n                              , plant_id == \"SUS00061\" ~ \"1001699\"\\n                              , plant_id == \"SUS00042\" ~ \"1004616\"\\n                              , plant_id == \"SUS00019\" ~ \"1002977\"\\n                              , plant_id == \"SUS00025\" ~ \"1007642\"\\n                              , plant_id == \"SUS00032\" ~ \"1007921\"\\n                              , plant_id == \"SUS00058\" ~ \"1007348\"\\n                              , plant_id == \"SUS00029\" ~ \"1005700\")\\n         , ghgrp_id = as.numeric(ghgrp_id)\\n         ) %>% \\n  left_join(scope1, by = \"ghgrp_id\") %>% \\n  select(-c(zip_code.x, zip_code.y)) %>% \\n  rename(scope1_co2e_tonnes_2021 = ghg_quantity_metric_tons_co2e)\\n  '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Anti-Joining to find remaining zip codes that had not matched and manually matching them\n",
    "remaining_zipcodes = pd.merge(zipcode_extraction, scope_1_and_2_zipcode_matches, on = \"zip_code\", how = \"left\", indicator = True)\n",
    "remaining_zipcodes = remaining_zipcodes[remaining_zipcodes['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "corrected_ghgids = remaining_zipcodes.copy()\n",
    "\n",
    "## Correctly matching the zip codes and assigning the plant id equivalents between both datasets \n",
    "ghgid_conditions = [\n",
    "  remaining_zipcodes['plant_id'] == \"SUS00002\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00007\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00015\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00042\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00019\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00025\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00032\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00058\"\n",
    ", remaining_zipcodes['plant_id'] == \"SUS00029\"\n",
    "]\n",
    "\n",
    "ghgid_choices = [\n",
    "  \"1003268\"\n",
    ", \"1003668\"\n",
    ", \"1000394\"\n",
    ", \"1004616\"\n",
    ", \"1002977\"\n",
    ", \"1007642\"\n",
    ", \"1007921\"\n",
    ", \"1007348\"\n",
    ", \"1005700\"]\n",
    "\n",
    "corrected_ghgids['ghgrp_id'] = np.select(ghgid_conditions, ghgid_choices, default=remaining_zipcodes['plant_id'])\n",
    "\n",
    "corrected_ghgids['ghgrp_id'] = pd.to_numeric(corrected_ghgids['ghgrp_id'])\n",
    "\n",
    "corrected_ghgids = pd.merge(corrected_ghgids, scope1, how = \"left\", on = \"ghgrp_id\").drop(columns = ['zip_code_x', 'zip_code_y']).rename(columns = {'ghg_quantity_metric_tons_co2e':'scope1_co2e_tonnes_2021'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all of our data to get a final dataset with scope 1 and 2 2021 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plant_id</th>\n",
       "      <th>plant_name</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>scope2_co2e_tonnes_2021</th>\n",
       "      <th>ghgrp_id</th>\n",
       "      <th>scope1_co2e_tonnes_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUS00002</td>\n",
       "      <td>Cleveland-Cliffs Butler steel plant</td>\n",
       "      <td>1 Armco Dr, Lyndora, PA 16045-1065, United States</td>\n",
       "      <td>40.845524</td>\n",
       "      <td>-79.921452</td>\n",
       "      <td>721591.62223</td>\n",
       "      <td>1003268</td>\n",
       "      <td>35074.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUS00007</td>\n",
       "      <td>Cleveland-Cliffs Coatesville steel plant</td>\n",
       "      <td>139 Modena Road, Coatesville, PA 19230, United...</td>\n",
       "      <td>39.977819</td>\n",
       "      <td>-75.824512</td>\n",
       "      <td>577273.29778</td>\n",
       "      <td>1003668</td>\n",
       "      <td>149470.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUS00015</td>\n",
       "      <td>Gerdau Petersburg Steel Mill</td>\n",
       "      <td>25801 Hofheimer Way, Petersburg, Virginia 2380...</td>\n",
       "      <td>37.181168</td>\n",
       "      <td>-77.449517</td>\n",
       "      <td>939248.32168</td>\n",
       "      <td>1000394</td>\n",
       "      <td>140045.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUS00019</td>\n",
       "      <td>North American Stainless steel plant</td>\n",
       "      <td>6870 Highway 42 East, Ghent, Kentucky, 41045-9...</td>\n",
       "      <td>38.725418</td>\n",
       "      <td>-85.076015</td>\n",
       "      <td>981950.05785</td>\n",
       "      <td>1002977</td>\n",
       "      <td>352251.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUS00025</td>\n",
       "      <td>Nucor Steel Hickman plant</td>\n",
       "      <td>5929 East State Highway 18, Armorel, Arkansas ...</td>\n",
       "      <td>35.901162</td>\n",
       "      <td>-89.776190</td>\n",
       "      <td>2301158.38811</td>\n",
       "      <td>1007642</td>\n",
       "      <td>454106.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUS00029</td>\n",
       "      <td>Nucor Steel Gallatin plant</td>\n",
       "      <td>4831 U.S. Hwy 42 W, Ghent, Kentucky 41405, Uni...</td>\n",
       "      <td>38.759878</td>\n",
       "      <td>-84.996204</td>\n",
       "      <td>891119.67750</td>\n",
       "      <td>1005700</td>\n",
       "      <td>219010.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUS00032</td>\n",
       "      <td>Nucor-Yamato Steel Blytheville plant</td>\n",
       "      <td>7301 East County Road 142, Blytheville, Arkans...</td>\n",
       "      <td>35.941421</td>\n",
       "      <td>-89.713819</td>\n",
       "      <td>2472101.58266</td>\n",
       "      <td>1007921</td>\n",
       "      <td>469008.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUS00042</td>\n",
       "      <td>Steel Dynamics Columbus plant</td>\n",
       "      <td>1945 Airport Road / P.O. Box 1467, Columbus, M...</td>\n",
       "      <td>33.447580</td>\n",
       "      <td>-88.572683</td>\n",
       "      <td>3193444.29371</td>\n",
       "      <td>1004616</td>\n",
       "      <td>575209.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUS00058</td>\n",
       "      <td>Optimus Steel Beaumont plant</td>\n",
       "      <td>PO BOX 3869, Beaumont, TX 77704, United States</td>\n",
       "      <td>30.08201</td>\n",
       "      <td>-94.074694</td>\n",
       "      <td>657473.82518</td>\n",
       "      <td>1007348</td>\n",
       "      <td>71537.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plant_id                                plant_name  \\\n",
       "0  SUS00002       Cleveland-Cliffs Butler steel plant   \n",
       "1  SUS00007  Cleveland-Cliffs Coatesville steel plant   \n",
       "2  SUS00015              Gerdau Petersburg Steel Mill   \n",
       "3  SUS00019      North American Stainless steel plant   \n",
       "4  SUS00025                 Nucor Steel Hickman plant   \n",
       "5  SUS00029                Nucor Steel Gallatin plant   \n",
       "6  SUS00032      Nucor-Yamato Steel Blytheville plant   \n",
       "7  SUS00042             Steel Dynamics Columbus plant   \n",
       "8  SUS00058              Optimus Steel Beaumont plant   \n",
       "\n",
       "                                             address        lat          lon  \\\n",
       "0  1 Armco Dr, Lyndora, PA 16045-1065, United States  40.845524   -79.921452   \n",
       "1  139 Modena Road, Coatesville, PA 19230, United...  39.977819   -75.824512   \n",
       "2  25801 Hofheimer Way, Petersburg, Virginia 2380...  37.181168   -77.449517   \n",
       "3  6870 Highway 42 East, Ghent, Kentucky, 41045-9...  38.725418   -85.076015   \n",
       "4  5929 East State Highway 18, Armorel, Arkansas ...  35.901162   -89.776190   \n",
       "5  4831 U.S. Hwy 42 W, Ghent, Kentucky 41405, Uni...  38.759878   -84.996204   \n",
       "6  7301 East County Road 142, Blytheville, Arkans...  35.941421   -89.713819   \n",
       "7  1945 Airport Road / P.O. Box 1467, Columbus, M...  33.447580   -88.572683   \n",
       "8     PO BOX 3869, Beaumont, TX 77704, United States   30.08201   -94.074694   \n",
       "\n",
       "   scope2_co2e_tonnes_2021  ghgrp_id  scope1_co2e_tonnes_2021  \n",
       "0             721591.62223   1003268              35074.00000  \n",
       "1             577273.29778   1003668             149470.00000  \n",
       "2             939248.32168   1000394             140045.00000  \n",
       "3             981950.05785   1002977             352251.00000  \n",
       "4            2301158.38811   1007642             454106.00000  \n",
       "5             891119.67750   1005700             219010.00000  \n",
       "6            2472101.58266   1007921             469008.00000  \n",
       "7            3193444.29371   1004616             575209.00000  \n",
       "8             657473.82518   1007348              71537.00000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_ghgids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('mikeys_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579423154b4eaee7bfe5a430418673f411175c3f3abce33f4969df0aa8270f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
